{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21239d5f",
   "metadata": {},
   "source": [
    "<h1><center><br> Text Classification with Naive Bayes </center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f17987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e0335",
   "metadata": {},
   "source": [
    "The dataset that we will work with is a selection of posts from scikit-learn's ['20 newsgroups' dataset](https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset). We will be working with just two of the 20 newsgroup categories:  'comp.graphics' (computer graphics) and 'rec.motorcycles' (recreation motorcycles). \n",
    "\n",
    "The cell below loads the data from a pickle file. The varaibles are:\n",
    "\n",
    "+ `Xtrain`: A list of documents used for training\n",
    "+ `ytrain`: The category of each training document\n",
    "+ `Xtest`: A list of documents used for testing\n",
    "+ `ytest`: The category of each testing document\n",
    "+ `categories`: The set of all categories\n",
    "+ `vocabulary`: The feature set, ie words used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f833154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Text_Classification.pickle','rb') as file:\n",
    "    Xtrain, ytrain, Xtest, ytest, categories, vocabulary = pickle.load(file)\n",
    "    \n",
    "N = Xtrain.shape[0]   # number of documents in the training corpus\n",
    "K = len(categories)   # number of document categories (classes)\n",
    "D = len(vocabulary)   # number of words in the vocabulary (features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc8d2f8",
   "metadata": {},
   "source": [
    "# 1. Find the number of training documents for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21bdfcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_per_category = dict.fromkeys(categories, 0)\n",
    "\n",
    "docs_per_category['comp.graphics'] = np.count_nonzero(ytrain == 'comp.graphics')\n",
    "docs_per_category['rec.motorcycles'] = np.count_nonzero(ytrain == 'rec.motorcycles')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e4fcf0",
   "metadata": {},
   "source": [
    "# 2. Create a bag-of-words representation for each document\n",
    "\n",
    "Our Naive Bayes algorithm will operate on a bag-of-words representation of each document. The first step is to write the `to_bow` method. \n",
    "\n",
    "The argument for this method is `doc`, which is an element of `X` (ie a string). It should return a `set` with the unique words that appear in both the document and the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e05827e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bow(doc):\n",
    "    bow = set()\n",
    "    \n",
    "    # Split `doc` at spaces using the the string's `split` method. Obtain a list.                             \n",
    "    bow_list = doc.split()\n",
    "    \n",
    "    # Keep only unique words from the list, by casting it as a set. \n",
    "    bow_set = set(bow_list)\n",
    "    \n",
    "    # From that set, keep only the ones that are present in the vocabulary.\n",
    "    bow = bow_set.intersection(vocabulary)\n",
    "    \n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "520effe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_bow = np.array([to_bow(doc) for doc in Xtrain])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f8082a",
   "metadata": {},
   "source": [
    "# 3. Compute the document count for each word in each category\n",
    "\n",
    "To estimate probabilities for Naive Bayes, we will need to know, for each category and each word, the number of documents of the category that contain the word. We will implement the `find_doc_counts_per_word_category` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09438ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_doc_counts_per_word_category(categories,vocabulary,ytrain,Xtrain_bow):\n",
    "\n",
    "    # Initialize the dictionary\n",
    "    doc_counters = dict.fromkeys(categories) \n",
    "    for category in categories:\n",
    "        doc_counters[category]  = dict.fromkeys(vocabulary,0)\n",
    "\n",
    "    # Loop through categories and documents in that category. \n",
    "    # For each word in the vocabulary that is also in the document, increment the corresponding counter by 1. \n",
    "    for category in categories:\n",
    "        \n",
    "        \n",
    "        # Filter Xtrain_bow and keep only the documents of this category\n",
    "        docs_in_category = Xtrain_bow[ytrain == category]\n",
    "\n",
    "        # For each document in the category, increment the appropriate counters\n",
    "        for doc in docs_in_category:\n",
    "            intsct = doc.intersection(vocabulary)\n",
    "            if len(intsct) != 0:\n",
    "                for word in intsct:\n",
    "                    doc_counters[category][word] += 1\n",
    "                    \n",
    "    return doc_counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e14d6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "doccount_per_cat_and_word = find_doc_counts_per_word_category(categories,vocabulary,ytrain,Xtrain_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab0636d",
   "metadata": {},
   "source": [
    "# 4. Find word frequencies per category\n",
    "\n",
    "We will write the `compute_word_freq` function. \n",
    "\n",
    "The argument for this method is the Laplace smoothing factor `alpha`. It also uses global variables, including `doccount_per_cat_and_word`.\n",
    "\n",
    "For each category and word, we will compute the Laplace-smoothed ratio of the number of documents containing the word, to the total number of documents in the category. \n",
    "\n",
    "Steps:\n",
    "\n",
    "1. For each category and word in the vocabulary, compute $\\rho_{d,k}$  as\n",
    "\n",
    "$$\\rho_{d,k} = \\frac{(\\text{# documents of category $k$ that contain word $d$}) + \\alpha}{(\\text{# documents of category $k$})+\\alpha K}$$\n",
    "\n",
    "Store it in `wordfreq[category][word]`.\n",
    "\n",
    "2. For each category, compute $\\rho_k$  as\n",
    "    \n",
    "$$\\rho_k = \\frac{\\text{# documents of category $k$}}{\\text{Total # documents}}$$\n",
    "\n",
    "Store it in `catfreq[category]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd3b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_freq(alpha):\n",
    "\n",
    "    D = len(vocabulary)\n",
    "\n",
    "    # Initialize `wordlogfreq` and `wordlogfreq`\n",
    "    wordfreq = dict.fromkeys(categories)\n",
    "    for category in categories:\n",
    "        wordfreq[category] = dict.fromkeys(vocabulary, 0)\n",
    "    ndocs = dict.fromkeys(categories)\n",
    "    catfreq = dict.fromkeys(categories)\n",
    "    \n",
    "    # Steps 1 and, compute wordlogfreq and doclogfreq\n",
    "    for category in categories:\n",
    "        ndocs[category] = docs_per_category[category]\n",
    "        \n",
    "        for word in vocabulary:\n",
    "            wordfreq[category][word] += (doccount_per_cat_and_word[category][word] + alpha) / (ndocs[category] + alpha * K)\n",
    "    \n",
    "        catfreq[category] = ndocs[category] / N\n",
    "    \n",
    "    return wordfreq, catfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62736735",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq, catfreq = compute_word_freq(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ede19f1",
   "metadata": {},
   "source": [
    "# 5. Write the Naive Bayes prediction function.\n",
    "\n",
    "Now we are computing the Naive Bayes prediction of the category for the given test document `xtest`. \n",
    "\n",
    "The arguments for this method are \n",
    "+ xtest: a single test document as a string.\n",
    "+ wordfreq, catfreq: the ratios computed in the previous step (with $\\alpha=0.1$)\n",
    "\n",
    "The steps for are:\n",
    "1. Find the BOW representation of `xtest`.\n",
    "\n",
    "2. Use the dictionary `score_cat` to store the score for each of the categories.\n",
    "\n",
    "3. Loop through categories, for each one compute its score with\n",
    "\n",
    "$$\\log\\rho_k+ \\sum_{d:\\:x_d=1} \\log\\rho_{d,k} + \\sum_{d:\\:x_d=0} \\log(1-\\rho_{d,k})$$\n",
    "\n",
    "Here $x_d$ is the $d$'th word in `xtest`\n",
    "\n",
    "4. Return the category with the highest score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b153b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Xtest, wordfreq, catfreq):\n",
    "\n",
    "    # 1. Find the BOW representation of Xtest.\n",
    "#     Xtest_bow = np.array([to_bow(doc) for doc in Xtest])\n",
    "#     for i in range(len(Xtest_bow) - 1):\n",
    "#         a = Xtest_bow[i].union(Xtest_bow[i + 1])\n",
    "    Xtest_bow = to_bow(Xtest)\n",
    "\n",
    "    # 2. Use a dictionary to store the score for each of the categories.\n",
    "    score_cat = dict.fromkeys(categories,0)\n",
    "\n",
    "    # 3. Loop through categories, for each one compute its score, and save it in score_cat.\n",
    "    for category in categories:\n",
    "        score_cat[category] += np.log(catfreq[category])\n",
    "        for word in vocabulary:\n",
    "            if word in Xtest_bow:\n",
    "                score_cat[category] += np.log(wordfreq[category][word])\n",
    "            else:\n",
    "                score_cat[category] += np.log(1 - wordfreq[category][word])\n",
    "\n",
    "    # 4. Return the category with the highest score.\n",
    "    return max(score_cat, key=score_cat.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9469a4",
   "metadata": {},
   "source": [
    "# 6. Compute accuracy\n",
    "\n",
    "Accuracy is defined as the number of correct predictions, divided by the total number of predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9de17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(Xin, yin, wordfreq, catfreq):\n",
    "\n",
    "    correct = 0\n",
    "    \n",
    "    # count the number of correct predictions\n",
    "    for i in range(len(Xin)):\n",
    "        if predict(Xin[i], wordfreq, catfreq) == yin[i]:\n",
    "            correct += 1\n",
    "        \n",
    "    return correct / len(Xin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf7e08",
   "metadata": {},
   "source": [
    "# 7. Compute the training and testing errors for a range of $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b81908",
   "metadata": {},
   "source": [
    "### 7.1. Train the model and compute its test accuracy for logarithmically spaced values of $\\alpha$ ranging from $10^{-5}$ to $10^1$\n",
    "\n",
    "Here 'training the model' means computing the Laplace-smoothed document frequencies with `compute_word_freq`. We will do this for a range of $\\alpha$'s and store their corresponding accuracies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21b3c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-5,1,20)\n",
    "acc = np.empty(len(alphas))\n",
    "for i in range(len(alphas)):\n",
    "    wordfreq, catfreq = compute_word_freq(alphas[i])\n",
    "    \n",
    "    acc[i] = compute_accuracy(Xtest, ytest, wordfreq, catfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3b70c",
   "metadata": {},
   "source": [
    "### 7.2. Plot the accuracies as a function of $\\alpha$ using `plt.semilogx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6015bc1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.semilogx(alphas, acc)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04943be1",
   "metadata": {},
   "source": [
    "### 7.3. Find the optimal $\\alpha$ and its corresponding accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0d4a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = acc[np.argmax(acc)]\n",
    "best_alpha = alphas[np.argmax(acc)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
